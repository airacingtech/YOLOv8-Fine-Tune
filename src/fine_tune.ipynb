{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import shutil\n",
    "import tqdm\n",
    "\n",
    "# Change these parameters to fit your needs\n",
    "EPOCHS = 100\n",
    "NUM_TRAIN_LOOPS = 1\n",
    "IMG_SIZE = 1032 # YOLOv8 default is 640\n",
    "LAYER_FREEZE = 0 # Number of layers to freeze\n",
    "\n",
    "# Amount to use different data augmentations\n",
    "HSV_H = 0.1  # Modifies hue\n",
    "HSV_S = 0.7  # Modifies saturation\n",
    "HSV_V = 0.4  # Modifies value (brightness)\n",
    "DEGREES = 0.4  # Rotates the image randomly\n",
    "TRANSLATE = 0.3\n",
    "SCALE = 0.5\n",
    "SHEAR = 0.01\n",
    "PERSPECTIVE = 0.001\n",
    "FLIPUD = 0.3\n",
    "FLIPLR = 0.3\n",
    "BGR = 0.1  # Flips channels from RGB to BGR\n",
    "MOSAIC = 0.5\n",
    "MIXUP = 0.5\n",
    "COPY_PASTE = 0.4\n",
    "ERASING = 0.2\n",
    "CROP_FRACTION = 0.1\n",
    "\n",
    "# Dictionary to weight dataset (randomly removed images with given probability\n",
    "# or duplicate images)\n",
    "DATASET_WEIGHTS = {\n",
    "    'large': 0.1 # Remove extra images from dataset with no frameskipping\n",
    "}\n",
    "\n",
    "# Whether or not to use hyperparameter tuning\n",
    "HYPERPARAMETER_TUNING = False\n",
    "# Whether or not to use ray tune for hyperparameter sweep / tuning\n",
    "USE_RAY_TUNE = False\n",
    "# Number of iterations for hyperparameter sweep / tuning\n",
    "TUNE_ITERS = 5\n",
    "\n",
    "CURR_DIR = os.getcwd()\n",
    "WORKSPACE_DIR = os.path.dirname(CURR_DIR)\n",
    "DATASETS_DIR = WORKSPACE_DIR + '/datasets/cvat_exported_id2/'\n",
    "DATA_YAML = WORKSPACE_DIR + '/data.yaml'\n",
    "\n",
    "# Percetnage of dataset to use for training\n",
    "TRAIN_PERCENTAGE = 1.0\n",
    "\n",
    "# Whether or not to keep empty frames (frames with no labels) in the dataset\n",
    "KEEP_EMPTY_FRAMES = True\n",
    "# Percentage of empty frames to keep in the dataset if KEEP_EMPTY_FRAMES is True (randomly sampled)\n",
    "PERCENTAGE_EMPTY_FRAMES_TO_KEEP = 0.8\n",
    "\n",
    "# Flag to resume training from a previous checkpoint (false if training from scratch)\n",
    "RESUME_TRAINING = False\n",
    "RESUME_TRAINING_PATH = WORKSPACE_DIR + 'runs/train/exp/weights/best.pt'\n",
    "# Size of YOLOv8 model\n",
    "MODEL_SIZE = 'n' # 'n' ,'s', 'm', 'l', 'x'\n",
    "\n",
    "# Path to trained model weights\n",
    "MODELS_PATH = WORKSPACE_DIR + '/models/'\n",
    "\n",
    "# This line prevents the Kernel from crashing when running model.train() which calls a plotting function\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "ONNX_BATCH_SIZE = 4\n",
    "\n",
    "# Todays data + Batch size + epochs\n",
    "DATE = time.strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA Available: \" + str(torch.cuda.is_available()))\n",
    "print(\"Torch CUDA Version: \" + str(torch.version.cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure CUDA is available and does not say \"None\"\n",
    "ultralytics.utils.checks.collect_system_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_empty_label(label_dst : os.PathLike) -> None:\n",
    "    '''\n",
    "    Generates an empty label file with the correct format to handle empty frames.\n",
    "    '''\n",
    "    with open(label_dst, 'w') as f:\n",
    "        f.write(\"\")\n",
    "\n",
    "def choose_dataset_weight(img_src : os.PathLike, dataset_weight : dict, weighted_frames : dict, frames_removed : dict) -> int:\n",
    "    '''\n",
    "    Returns a dataset weight to use dataset_weights dictionary. Uses the file path to determine the dataset.\n",
    "    '''\n",
    "    dataset_name = img_src.split(\"/\")[-3]\n",
    "    for dataset, weight in dataset_weight.items():\n",
    "        if dataset in dataset_name:\n",
    "            # If weight is greater than 1, keep the frame and create additional frames with the same image and label\n",
    "            if weight > 1:\n",
    "                weighted_frames[dataset] = weighted_frames.get(dataset, 0) + (weight - 1)\n",
    "                return weight\n",
    "            # If weight is less than 1, randomly choose to keep the frame or not\n",
    "            else:\n",
    "                # Keep the frame with probability weight\n",
    "                if random.random() < weight:\n",
    "                    return 1\n",
    "                # Discard the frame with probability 1 - weight\n",
    "                else:\n",
    "                    frames_removed[dataset] = frames_removed.get(dataset, 0) + 1\n",
    "                    return 0\n",
    "    return 1\n",
    "\n",
    "def copy_data_yaml(label_src : os.PathLike, img_src : os.PathLike, label_dst : os.PathLike, img_dst : os.PathLike, empty_frames_kept : int, weighted_frames : dict, frames_removed : dict) -> None:\n",
    "    '''\n",
    "    Copies the images and labels from one directory to another. Also handles the case where the label file is empty (i.e. does not exist).\n",
    "    '''\n",
    "    if not os.path.exists(label_src):\n",
    "        # print(\"Empty label file detected:\", label_src)\n",
    "        if KEEP_EMPTY_FRAMES:\n",
    "            if random.random() < PERCENTAGE_EMPTY_FRAMES_TO_KEEP:\n",
    "                empty_frames_kept += 1\n",
    "                for i in range(choose_dataset_weight(img_src, DATASET_WEIGHTS, weighted_frames, frames_removed)):\n",
    "                    img_dst_with_weight = img_dst[:-4] + \"_\" + str(i) + \".jpg\"\n",
    "                    label_dst_with_weight = label_dst[:-4] + \"_\" + str(i) + \".txt\"\n",
    "                    shutil.copy(img_src, img_dst_with_weight)\n",
    "                    generate_empty_label(label_dst_with_weight)\n",
    "                    # normalize_image(img_dst)\n",
    "    else:\n",
    "        for i in range(choose_dataset_weight(img_src, DATASET_WEIGHTS, weighted_frames, frames_removed)):\n",
    "            img_dst_with_weight = img_dst[:-4] + \"_\" + str(i) + \".jpg\"\n",
    "            label_dst_with_weight = label_dst[:-4] + \"_\" + str(i) + \".txt\"\n",
    "            shutil.copy(img_src, img_dst_with_weight)\n",
    "            shutil.copy(label_src, label_dst_with_weight)\n",
    "            # normalize_image(img_dst)\n",
    "\n",
    "def normalize_image(img_path : os.PathLike) -> None:\n",
    "    '''\n",
    "    Normalizes the image to the correct format for YOLOv8.\n",
    "    '''\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (640, 640))\n",
    "    cv2.imwrite(img_path, img)\n",
    "\n",
    "def format_datasets(datasets_path : os.PathLike, data_yaml : os.PathLike) -> None:\n",
    "    \"\"\"\n",
    "    Takes in a directory of datasets where each dataset is in the format of a COCO dataset\n",
    "    and then formats the datasets into a single dataset that YOLOv8 can use for training\n",
    "    placed in the 'data/' directory. This function will delete the 'data/' directory and recreate\n",
    "    it. The data.yaml file must be created manually and will be copied over to the 'data/'\n",
    "    directory. The function will also split the data into training, validation, and test sets.\n",
    "        \n",
    "    Args:\n",
    "        datasets_path (os.PathLike): The path to the directory containing the datasets.\n",
    "        data_yaml (os.PathLike): The path to the data.yaml file specifying the dataset. This must be\n",
    "            created manually.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    assert os.path.exists(datasets_path), f\"The dataset path, {datasets_path}, does not exist.\"\n",
    "    assert os.path.exists(data_yaml), f\"The data.yaml file, {data_yaml}, does not exist.\"\n",
    "\n",
    "    print(\"Extracting sim images from:\", datasets_path, \"for training/validation data\")\n",
    "\n",
    "    # Get all images and labels from the datasets\n",
    "    datasets_labels = []\n",
    "    for dataset_path in os.listdir(datasets_path):\n",
    "        full_path = os.path.join(datasets_path, dataset_path)\n",
    "        for img_file in os.listdir(full_path + \"/images/\"):\n",
    "            datasets_labels.append([full_path + \"/images/\" + img_file, full_path + \"/labels/\" + img_file[:-4] + \".txt\", dataset_path])\n",
    "\n",
    "    # Sort images by filename\n",
    "    datasets_labels = sorted(datasets_labels, key = lambda x: x[0])\n",
    "    # datasets_labels = sorted(datasets_labels, key = lambda x: x[0])\n",
    "\n",
    "    # Shuffle images deterministically with seed\n",
    "    random.seed(0)\n",
    "    random.shuffle(datasets_labels)\n",
    "\n",
    "    # Split 70% training, 20% validation, 10% test\n",
    "    training_data = datasets_labels[:len(datasets_labels) * 7 // 10]\n",
    "    valid_data = datasets_labels[len(datasets_labels) * 7 // 10 :len(datasets_labels) * 9 // 10]\n",
    "    test_data = datasets_labels[len(datasets_labels) * 9 // 10 :]\n",
    "\n",
    "\n",
    "    # Create the directories for the training, validation, and test data\n",
    "    if os.path.exists(\"../data/\"):\n",
    "        print(\"Deleting and recreating 'data/' folder...\")\n",
    "        shutil.rmtree(\"../data/\")\n",
    "    os.mkdir(\"../data/\")\n",
    "    os.mkdir(\"../data/train/\")\n",
    "    os.mkdir(\"../data/train/images/\")\n",
    "    os.mkdir(\"../data/train/labels/\")\n",
    "    os.mkdir(\"../data/valid/\")\n",
    "    os.mkdir(\"../data/valid/images/\")\n",
    "    os.mkdir(\"../data/valid/labels/\")\n",
    "    os.mkdir(\"../data/test/\")\n",
    "    os.mkdir(\"../data/test/images/\")\n",
    "    os.mkdir(\"../data/test/labels/\")\n",
    "\n",
    "    # Copy over images and labels to new directories\n",
    "    print(\"Copying images and labels to new directories...\")\n",
    "    print(\"Copying training data:\")\n",
    "\n",
    "    # Create a new image number to avoid overwriting images in the same chance they have the same name\n",
    "    new_image_uuid = 0\n",
    "    empty_frames_kept = 0\n",
    "    weighted_frames = {}\n",
    "    removed_frames = {}\n",
    "    train_frames = 0\n",
    "    valid_frames = 0\n",
    "    test_frames = 0\n",
    "    for img_src, label_src, dataset_path in tqdm.tqdm(training_data):\n",
    "        if (random.random() < TRAIN_PERCENTAGE):\n",
    "            new_image_name = img_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".jpg\"\n",
    "            new_label_name = label_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".txt\"\n",
    "            img_dst = os.path.join(\"../data/train/images/\", dataset_path + \"_\" + new_image_name)\n",
    "            label_dst = os.path.join(\"../data/train/labels/\", dataset_path + \"_\" + new_label_name)\n",
    "            copy_data_yaml(label_src, img_src, label_dst, img_dst, empty_frames_kept, weighted_frames, removed_frames)\n",
    "            new_image_uuid += 1\n",
    "            train_frames += 1\n",
    "    for img_src, label_src, dataset_path in tqdm.tqdm(valid_data):\n",
    "        new_image_name = img_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".jpg\"\n",
    "        new_label_name = label_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".txt\"\n",
    "        img_dst = os.path.join(\"../data/valid/images/\", dataset_path + \"_\" + new_image_name)\n",
    "        label_dst = os.path.join(\"../data/valid/labels/\", dataset_path + \"_\" + new_label_name)\n",
    "        copy_data_yaml(label_src, img_src, label_dst, img_dst, empty_frames_kept, weighted_frames, removed_frames)\n",
    "        new_image_uuid += 1\n",
    "        valid_frames += 1\n",
    "    for img_src, label_src, dataset_path in tqdm.tqdm(test_data):\n",
    "        new_image_name = img_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".jpg\"\n",
    "        new_label_name = label_src.split(\"/\")[-1][:-4] + \"_\" + str(new_image_uuid) + \".txt\"\n",
    "        img_dst = os.path.join(\"../data/test/images/\", dataset_path + \"_\" + new_image_name)\n",
    "        label_dst = os.path.join(\"../data/test/labels/\", dataset_path + \"_\" + new_label_name)\n",
    "        copy_data_yaml(label_src, img_src, label_dst, img_dst, empty_frames_kept, weighted_frames, removed_frames)\n",
    "        new_image_uuid += 1\n",
    "        test_frames += 1\n",
    "\n",
    "    # Copy over data.yaml file from root directory\n",
    "    shutil.copy(data_yaml, \"../data/\")\n",
    "    print(\"Copied over 'data.yaml' file\")\n",
    "    print(\"Number of empty frames kept: \", empty_frames_kept)\n",
    "\n",
    "    print(\"Number of training frames: \", train_frames)\n",
    "    print(\"Number of validation frames: \", valid_frames)\n",
    "    print(\"Number of test frames: \", test_frames)\n",
    "    print(\"Additional weighted frames created for each dataset: \", weighted_frames)\n",
    "    print(\"Number of frames removed for each dataset: \", removed_frames)\n",
    "    print(\"Finished creating directories for YOLOv8 training pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_datasets(DATASETS_DIR, DATA_YAML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_model_size() -> str:\n",
    "    \"\"\"\n",
    "    Takes the global variable MODEL_SIZE and returns the corresponding string\n",
    "    to pass to the YOLO class and print the model parameter size.\n",
    "\n",
    "    Returns:\n",
    "        str: The model string to pass to the YOLO class.\n",
    "    \"\"\"\n",
    "    if MODEL_SIZE == 'n':\n",
    "        print(\"Using YOLOv8 Nano model\")\n",
    "        return 'yolov8n-seg.pt'\n",
    "    elif MODEL_SIZE == 's':\n",
    "        print(\"Using YOLOv8 Small model\")\n",
    "        return 'yolov8s-seg.pt'\n",
    "    elif MODEL_SIZE == 'm':\n",
    "        print(\"Using YOLOv8 Medium model\")\n",
    "        return 'yolov8m-seg.pt'\n",
    "    elif MODEL_SIZE == 'l':\n",
    "        print(\"Using YOLOv8 Large model\")\n",
    "        return 'yolov8l-seg.pt'\n",
    "    elif MODEL_SIZE == 'x':\n",
    "        print(\"Using YOLOv8 Extra Large model\")\n",
    "        return 'yolov8x-seg.pt'\n",
    "    \n",
    "# Load yolov8 nano segmentation model\n",
    "if RESUME_TRAINING:\n",
    "    model = YOLO(RESUME_TRAINING_PATH)\n",
    "# Load yolov8 nano segmentation model\n",
    "else:\n",
    "    model = YOLO(choose_model_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dataset images\n",
    "data_dir = CURR_DIR + '/../data/'\n",
    "curr_data_yaml = data_dir + 'data.yaml'\n",
    "TEST_PATH = data_dir + '/test/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model : YOLO) -> None:\n",
    "    start_time = time.time()\n",
    "    model_name = f'yolov8{MODEL_SIZE}-img_size_{IMG_SIZE}_layers_frozen_{LAYER_FREEZE}_{DATE}'\n",
    "    # By default, the model trains on a single GPU\n",
    "    model.train(\n",
    "        data=curr_data_yaml,\n",
    "        imgsz=IMG_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        freeze=LAYER_FREEZE,\n",
    "        amp=True,\n",
    "        cache=\"disk\", # If the size of your dataset is larger than your available memory, cache to disk instead with cache=\"disk\", else use cache=True to keep the dataset in memory\n",
    "        save=True,\n",
    "        save_period=10,\n",
    "        name=model_name,\n",
    "        hsv_h=HSV_H,\n",
    "        hsv_s=HSV_S,\n",
    "        hsv_v=HSV_V,\n",
    "        degrees=DEGREES,\n",
    "        translate=TRANSLATE,\n",
    "        scale=SCALE,\n",
    "        shear=SHEAR,\n",
    "        perspective=PERSPECTIVE,\n",
    "        flipud=FLIPUD,\n",
    "        fliplr=FLIPLR,\n",
    "        # bgr=BGR,\n",
    "        mosaic=MOSAIC,\n",
    "        mixup=MIXUP,\n",
    "        copy_paste=COPY_PASTE,\n",
    "        erasing=ERASING,\n",
    "        crop_fraction=CROP_FRACTION\n",
    "    )\n",
    "                \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(\"Time to train: \", training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(model : YOLO) -> None:\n",
    "    # Runs a hyperparameter sweep and selects the best hyperparameters\n",
    "    if HYPERPARAMETER_TUNING:\n",
    "        model.tune(use_ray=USE_RAY_TUNE, iterations=TUNE_ITERS)\n",
    "    else:\n",
    "        print(\"Skipping hyperparameter tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model : YOLO, test_results_path: os.PathLike) -> None:\n",
    "    \"\"\"\n",
    "    Test the fine-tuned model on test images and save the results.\n",
    "\n",
    "    Parameters:\n",
    "        model (YOLO): The fine-tuned YOLO model.\n",
    "        test_results_path (os.PathLike): The path to save the test results.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    # Make sure the test save path exists\n",
    "    if not os.path.exists(test_results_path):\n",
    "        os.makedirs(test_results_path)\n",
    "\n",
    "    # Inferencee fine-tuned model on test images and save results\n",
    "    for file in os.listdir(TEST_PATH):\n",
    "        file_path = os.path.join(TEST_PATH, file)\n",
    "        output = model.predict(file_path)\n",
    "        save_path = os.path.join(test_results_path, file)\n",
    "        cv2.imwrite(save_path, output[0].plot())\n",
    "\n",
    "    print(\"Inference on test set complete. Results saved to: \", test_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_done = 0\n",
    "for _ in range(NUM_TRAIN_LOOPS):\n",
    "    print(f\"Starting training loop starting on epoch {epochs_done}\")\n",
    "    train_model(model)\n",
    "    epochs_done += EPOCHS\n",
    "    tune_model(model)\n",
    "    test_results_path = data_dir + '/test/annotation_results' + f'_{epochs_done}epochs'\n",
    "    test_model(model, test_results_path)\n",
    "    model_name = f\"yolov8{MODEL_SIZE}_{DATE}_batch{ONNX_BATCH_SIZE}_{EPOCHS}epochs\"\n",
    "    model_path = MODELS_PATH + model_name + '.pt'\n",
    "    model.save(model_path)\n",
    "    # Export the model as an .onnx file\n",
    "    model.export(format='onnx', batch=ONNX_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Weights and Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model as an .onnx file\n",
    "model.export(format='onnx', batch=ONNX_BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
